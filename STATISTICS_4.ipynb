{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obug0mG-jC2S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
        "an example.**"
      ],
      "metadata": {
        "id": "vOLqtPpijI-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sure! The Probability Mass Function (PMF) and Probability Density Function (PDF) are mathematical concepts used in probability and statistics to describe the likelihood of different outcomes in a random variable.\n",
        "\n",
        "1. **Probability Mass Function (PMF)**:\n",
        "   - The PMF is applicable to discrete random variables, which means the variable can only take on specific, distinct values.\n",
        "   - It gives the probability that a discrete random variable is exactly equal to some value.\n",
        "   - Mathematically, if X is a discrete random variable, then the PMF is denoted by P(X=x), where x represents the specific value of the random variable.\n",
        "   - The sum of probabilities over all possible values of the random variable equals 1.\n",
        "   \n",
        "   **Example**: Suppose we have a fair six-sided die. The PMF for this die assigns probabilities to each possible outcome (1, 2, 3, 4, 5, or 6). Since it's a fair die, the PMF for each outcome is 1/6. So, if we denote the random variable X as the outcome of a single roll of the die, the PMF would be:\n",
        "   \n",
        "   P(X=1) = 1/6  \n",
        "   P(X=2) = 1/6  \n",
        "   P(X=3) = 1/6  \n",
        "   P(X=4) = 1/6  \n",
        "   P(X=5) = 1/6  \n",
        "   P(X=6) = 1/6  \n",
        "   \n",
        "   And the sum of all these probabilities would equal 1.\n",
        "\n",
        "2. **Probability Density Function (PDF)**:\n",
        "   - The PDF is used for continuous random variables, where the variable can take on any value within a certain range.\n",
        "   - It represents the likelihood of the random variable falling within a particular interval.\n",
        "   - Unlike the PMF, which gives the probability at a specific point, the PDF gives the probability density at that point.\n",
        "   - The area under the PDF curve over a given interval represents the probability that the random variable falls within that interval.\n",
        "   \n",
        "   **Example**: Consider the height of adult humans. Heights can be any real number within a certain range (e.g., from 4 feet to 7 feet). The PDF for height might follow a normal distribution, with the peak indicating the most common height and the spread indicating how heights are distributed around the mean. In this case, the PDF gives the probability density at each height value within the range.\n",
        "\n",
        "These functions are fundamental in probability and statistics, aiding in understanding and analyzing random phenomena."
      ],
      "metadata": {
        "id": "9j_UHgVQjfAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?**"
      ],
      "metadata": {
        "id": "WzQtrHSJjgIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Cumulative Distribution Function (CDF) is a concept in probability theory that describes the probability that a random variable takes on a value less than or equal to a given value. In simpler terms, it gives the cumulative probability up to a certain point.\n",
        "\n",
        "\n",
        "The CDF is used for various purposes in probability theory and statistics:\n",
        "\n",
        "1. **Probability Calculations**: It allows us to calculate the probability of a random variable falling within a specified range of values.\n",
        "2. **Descriptive Statistics**: CDFs provide a concise summary of the distribution of a random variable, including measures such as the median and quartiles.\n",
        "3. **Hypothesis Testing**: In statistical hypothesis testing, CDFs are used to compute critical values and determine the significance of test statistics.\n",
        "4. **Model Evaluation**: CDFs can be used to compare observed data with theoretical distributions or model predictions.\n",
        "5. **Random Number Generation**: CDFs are used in inverse transform sampling to generate random numbers with a specified distribution.\n",
        "\n",
        "**Example**: Let's consider the example of rolling a fair six-sided die. The CDF for this scenario can be calculated as follows:\n",
        "\n",
        "- F(1) is the probability that the outcome is less than or equal to 1, which is  1/6.\n",
        "- \\( F(2) \\) is the probability that the outcome is less than or equal to 2, which is 2/6 = 1/6\n",
        "- Similarly, we can calculate  F(3), F(4) , F(5) , and F(6)  using the probabilities associated with each outcome.\n",
        "\n",
        "In summary, the Cumulative Distribution Function (CDF) is a fundamental concept in probability theory and statistics, providing insights into the behavior of random variables and their probability distributions."
      ],
      "metadata": {
        "id": "Jy8qF-NUp2wM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
        "Explain how the parameters of the normal distribution relate to the shape of the distribution.**"
      ],
      "metadata": {
        "id": "ICC7TlrgqopH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The normal distribution, also known as the Gaussian distribution, is widely used to model continuous random variables in various real-world situations. Here are some examples of situations where the normal distribution might be used as a model:\n",
        "\n",
        "1. **Biological Measurements**: Many biological measurements, such as heights, weights, blood pressure, and IQ scores, often follow a normal distribution within a population. For example, the heights of adult humans in a given population tend to be normally distributed, with most individuals clustered around the average height.\n",
        "\n",
        "2. **Financial Data**: In finance, variables such as stock prices, returns on investments, and interest rates often exhibit a normal distribution, especially when considering large portfolios or aggregates of assets. For instance, daily stock returns for a particular company over a long period may be approximately normally distributed.\n",
        "\n",
        "3. **Quality Control**: Measurements of product dimensions, defects, or process outputs in manufacturing processes often exhibit a normal distribution. Quality control engineers use the normal distribution to model variations in product quality and to set quality control limits.\n",
        "\n",
        "4. **Educational Testing**: Test scores on standardized exams, such as the SAT, GRE, or IQ tests, are often assumed to follow a normal distribution within a population of test-takers. This assumption allows for the comparison of individual test scores relative to the population.\n",
        "\n",
        "5. **Natural Phenomena**: Various natural phenomena, such as the distribution of particle velocities in a gas, errors in scientific measurements, and environmental variables like temperature or rainfall, can be modeled using the normal distribution.\n",
        "\n",
        "The parameters of the normal distribution, namely the mean (\\( \\mu \\)) and the standard deviation (\\( \\sigma \\)), determine the shape of the distribution:\n",
        "\n",
        "- **Mean (\\( \\mu \\))**: The mean represents the center of the distribution. It determines the location of the peak (mode) of the distribution. Shifting the mean to the right or left moves the entire distribution along the horizontal axis.\n",
        "\n",
        "- **Standard Deviation (\\( \\sigma \\))**: The standard deviation measures the spread or dispersion of the distribution. A larger standard deviation results in a wider and flatter distribution, while a smaller standard deviation results in a narrower and taller distribution. It quantifies how much individual data points deviate from the mean.\n",
        "\n",
        "In summary, the normal distribution is commonly used to model a wide range of continuous random variables in various fields, and its parameters play a crucial role in determining the shape and characteristics of the distribution."
      ],
      "metadata": {
        "id": "sCsOoFgCrD8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
        "Distribution.**"
      ],
      "metadata": {
        "id": "F748AokWrVjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The normal distribution, also known as the Gaussian distribution, holds significant importance in statistics, probability theory, and various fields of science and engineering. Its importance stems from several key characteristics:\n",
        "\n",
        "1. **Central Limit Theorem**: One of the most important properties of the normal distribution is its connection to the Central Limit Theorem (CLT). The CLT states that the distribution of the sum (or average) of a large number of independent and identically distributed random variables approaches a normal distribution, regardless of the original distribution of the variables. This theorem is fundamental in statistical inference, as it allows for the approximation of many real-world phenomena by the normal distribution.\n",
        "\n",
        "2. **Modeling Uncertainty**: Many natural and human-made processes exhibit variability and uncertainty that can be effectively modeled using the normal distribution. It provides a convenient framework for describing the randomness and fluctuations observed in real-life data.\n",
        "\n",
        "3. **Statistical Inference**: In parametric statistical inference, the assumption of normality is often made for population distributions. This assumption facilitates the use of parametric tests such as t-tests, ANOVA, and linear regression. These tests rely on the assumption of normality for valid inference.\n",
        "\n",
        "4. **Quality Control and Process Improvement**: Normal distributions are commonly used in quality control to model process variability and identify deviations from expected performance. Control charts and process capability indices are based on the assumption of normally distributed data.\n",
        "\n",
        "5. **Risk Management and Finance**: In finance and risk management, many variables such as stock returns, interest rates, and asset prices are assumed to follow a normal distribution or are approximated by it. This assumption allows for the calculation of risk measures such as value-at-risk (VaR) and the pricing of financial derivatives.\n",
        "\n",
        "Examples of real-life phenomena that can be modeled using the normal distribution include:\n",
        "\n",
        "- **Height of Individuals**: The distribution of heights in a population often follows a normal distribution, with most individuals clustered around the average height and fewer individuals at the extremes.\n",
        "  \n",
        "- **IQ Scores**: Intelligence quotient (IQ) scores are standardized to follow a normal distribution with a mean of 100 and a standard deviation of 15. This distribution allows for the comparison of an individual's IQ relative to the population.\n",
        "\n",
        "- **Blood Pressure**: Blood pressure measurements in a population typically exhibit a bell-shaped distribution around a central value, with most individuals having blood pressure values close to the average.\n",
        "\n",
        "- **Exam Scores**: Test scores on standardized exams such as the SAT or GRE are often assumed to follow a normal distribution within a population of test-takers.\n",
        "\n",
        "In summary, the normal distribution is a fundamental concept in statistics and provides a powerful tool for modeling uncertainty, making predictions, and making statistical inferences in various real-life contexts. Its versatility and applicability make it a cornerstone of statistical theory and practice."
      ],
      "metadata": {
        "id": "KmenXMsRrUOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
        "Distribution and Binomial Distribution?**\n"
      ],
      "metadata": {
        "id": "ziWuAhCBrari"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Bernoulli distribution is a discrete probability distribution that models the outcomes of a single Bernoulli trial, which has only two possible outcomes: success or failure. It is named after the Swiss mathematician Jacob Bernoulli. The distribution is characterized by a single parameter \\( p \\), which represents the probability of success.\n",
        "\n",
        "The probability mass function (PMF) of the Bernoulli distribution is:\n",
        "\n",
        "\\[ P(X = x) =\n",
        "\\begin{cases}\n",
        "p & \\text{if } x = 1 \\\\\n",
        "1-p & \\text{if } x = 0 \\\\\n",
        "0 & \\text{otherwise}\n",
        "\\end{cases}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( X \\) is the random variable representing the outcome of the Bernoulli trial.\n",
        "- \\( p \\) is the probability of success (i.e., the probability of \\( X = 1 \\)).\n",
        "- \\( 1-p \\) is the probability of failure (i.e., the probability of \\( X = 0 \\)).\n",
        "\n",
        "**Example**: A single flip of a fair coin can be modeled using a Bernoulli distribution. Let's define success (1) as obtaining a heads and failure (0) as obtaining a tails. If the probability of getting heads (success) is \\( p = 0.5 \\), then the Bernoulli distribution for this coin flip is:\n",
        "\n",
        "\\[ P(X = x) =\n",
        "\\begin{cases}\n",
        "0.5 & \\text{if } x = 1 \\text{ (heads)} \\\\\n",
        "0.5 & \\text{if } x = 0 \\text{ (tails)} \\\\\n",
        "0 & \\text{otherwise}\n",
        "\\end{cases}\n",
        "\\]\n",
        "\n",
        "The key difference between the Bernoulli distribution and the binomial distribution lies in the number of Bernoulli trials involved:\n",
        "\n",
        "1. **Bernoulli Distribution**:\n",
        "   - Describes the outcomes of a single Bernoulli trial, with only two possible outcomes: success or failure.\n",
        "   - Has a single parameter \\( p \\), representing the probability of success.\n",
        "   - The random variable \\( X \\) takes on values of 0 or 1 (failure or success).\n",
        "   - It is a special case of the binomial distribution when the number of trials is 1.\n",
        "\n",
        "2. **Binomial Distribution**:\n",
        "   - Describes the number of successes in a fixed number of independent Bernoulli trials.\n",
        "   - Involves repeating a Bernoulli experiment \\( n \\) times, where each trial is independent and has the same probability of success \\( p \\).\n",
        "   - The binomial distribution has two parameters: \\( n \\), the number of trials, and \\( p \\), the probability of success on each trial.\n",
        "   - The random variable \\( X \\) represents the number of successes, and it can take on integer values from 0 to \\( n \\).\n",
        "\n",
        "In summary, while the Bernoulli distribution models a single Bernoulli trial, the binomial distribution models the number of successes in multiple independent trials, each following a Bernoulli distribution."
      ],
      "metadata": {
        "id": "Sz7cDI6cr52s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
        "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
        "than 60? Use the appropriate formula and show your calculations.**"
      ],
      "metadata": {
        "id": "XngoJA93sBoY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the probability that a randomly selected observation from a normally distributed dataset with a mean (\\( \\mu \\)) of 50 and a standard deviation (\\( \\sigma \\)) of 10 will be greater than 60, we can use the standard normal distribution formula and Z-score.\n",
        "\n",
        "The Z-score formula is given by:\n",
        "\n",
        " Z = X−μ/σ\n",
        "\n",
        "\n",
        "Where:\n",
        "-  X  is the value we're interested in (in this case, 60),\n",
        "- μis the mean of the dataset (50),\n",
        "- σ is the standard deviation of the dataset (10).\n",
        "\n",
        "First, we calculate the Z-score:\n",
        "\n",
        " Z =60-50/10\n",
        "\n",
        "Once we have the Z-score, we can find the probability using the standard normal distribution table or a calculator. The probability of a Z-score being greater than 1 can be found by subtracting the cumulative probability from 1:\n",
        "\n",
        " P(Z > 1) = 1 - P(Z <=1 )\n",
        "\n",
        "Now, we look up the cumulative probability for \\( Z = 1 \\) in the standard normal distribution table or use a calculator. Typically, this value is approximately 0.8413.\n",
        "\n",
        " P(Z > 1) 1 - 0.8413 = 0.1587\n",
        "\n",
        "Therefore, the probability that a randomly selected observation from the dataset will be greater than 60 is approximately 0.1587, or 15.87%."
      ],
      "metadata": {
        "id": "gUcrCzo4IxWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7: Explain uniform Distribution with an example.t**"
      ],
      "metadata": {
        "id": "masV8dfYJouY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The uniform distribution is a continuous probability distribution where all outcomes within a given range are equally likely. In other words, each value within the range has the same probability of occurring. It is characterized by two parameters: the minimum value (\\( a \\)) and the maximum value (\\( b \\)).\n",
        "\n",
        "The probability density function (PDF) of the uniform distribution is constant within the range \\([a, b]\\) and zero outside this range. Mathematically, the PDF of a uniform distribution is given by:\n",
        "\n",
        " f(x) = 1/(a-b)\n",
        "\n",
        "Where:\n",
        "- a is the minimum value of the range.\n",
        "- b is the maximum value of the range.\n",
        "- x is the random variable within the range \\([a, b]\\).\n",
        "- f(x) is the probability density function.\n",
        "\n",
        "The cumulative distribution function (CDF) of the uniform distribution is a piecewise function that increases linearly from 0 to 1 within the range \\([a, b]\\).\n",
        "\n",
        "**Example**: Let's consider an example of rolling a fair six-sided die. If the die is fair, each outcome (1, 2, 3, 4, 5, or 6) has an equal probability of \\( \\frac{1}{6} \\). This situation can be modeled using a discrete uniform distribution with parameters \\( a = 1 \\) and \\( b = 6 \\).\n",
        "\n",
        "In this example:\n",
        "- \\( a = 1 \\) is the minimum value of the range (the lowest possible outcome of rolling the die).\n",
        "- \\( b = 6 \\) is the maximum value of the range (the highest possible outcome of rolling the die).\n",
        "- The probability density function \\( f(x) \\) for each outcome \\( x \\) between 1 and 6 is 1/6, indicating that each outcome is equally likely.\n",
        "- The cumulative distribution function (CDF) increases linearly from 0 to 1 within the range \\([1, 6]\\), indicating the cumulative probability of each outcome.\n",
        "\n",
        "In summary, the uniform distribution is a simple and intuitive probability distribution where all outcomes within a given range are equally likely. It is commonly used in various fields such as statistics, physics, and computer science to model situations where randomness is uniform across the range."
      ],
      "metadata": {
        "id": "CG35rsfJJ7D9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8: What is the z score? State the importance of the z score.**"
      ],
      "metadata": {
        "id": "va6FefHeKNix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Z-score, also known as the standard score, is a dimensionless measure that indicates how many standard deviations a data point is from the mean of a dataset. It is calculated by subtracting the mean of the dataset from the individual data point and then dividing the result by the standard deviation of the dataset. Mathematically, the Z-score for a data point \\( x \\) is given by:\n",
        "\n",
        "\\[ Z = \\frac{{x - \\mu}}{{\\sigma}} \\]\n",
        "\n",
        "Where:\n",
        "- \\( Z \\) is the Z-score.\n",
        "- \\( x \\) is the individual data point.\n",
        "- \\( \\mu \\) is the mean of the dataset.\n",
        "- \\( \\sigma \\) is the standard deviation of the dataset.\n",
        "\n",
        "The Z-score indicates whether a data point is above or below the mean and how far it is from the mean in terms of standard deviations. A positive Z-score indicates that the data point is above the mean, while a negative Z-score indicates that the data point is below the mean.\n",
        "\n",
        "**Importance of the Z-score**:\n",
        "\n",
        "1. **Standardization**: Z-scores are used to standardize data by transforming it into a common scale with a mean of 0 and a standard deviation of 1. This standardization allows for easier comparison and interpretation of data from different datasets or variables.\n",
        "\n",
        "2. **Outlier Detection**: Z-scores can help identify outliers in a dataset. Data points with Z-scores that are significantly higher or lower than the mean may indicate unusual or extreme observations that warrant further investigation.\n",
        "\n",
        "3. **Statistical Inference**: Z-scores are used in hypothesis testing and statistical inference to assess the significance of differences or relationships between variables. They provide a standardized measure of deviation from the mean, allowing for more meaningful comparisons and interpretations of statistical results.\n",
        "\n",
        "4. **Probability Calculations**: Z-scores are used to calculate probabilities associated with specific data values in a normal distribution. By standardizing data to Z-scores, researchers can easily determine the probability of observing a data point within a certain range or above/below a certain threshold.\n",
        "\n",
        "5. **Data Analysis and Interpretation**: Z-scores provide a useful tool for data analysis and interpretation in various fields such as finance, healthcare, and education. They help researchers and practitioners understand the relative position and significance of data points within a dataset, leading to more informed decision-making.\n",
        "\n",
        "In summary, the Z-score is a valuable statistical tool that standardizes data, facilitates comparison and interpretation, aids in outlier detection, supports statistical inference, and enables probability calculations. Its widespread use across different disciplines highlights its importance in data analysis and decision-making processes."
      ],
      "metadata": {
        "id": "QsyC8IwvKil-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.**"
      ],
      "metadata": {
        "id": "mk2oPlk6KnwQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of the sampling distribution of the sample mean or the sum of a large number of independent and identically distributed (i.i.d.) random variables. It states that, regardless of the shape of the population distribution, the sampling distribution of the sample mean or sum approaches a normal distribution as the sample size increases, assuming the sample size is sufficiently large.\n",
        "\n",
        "Mathematically, the Central Limit Theorem can be stated as follows:\n",
        "\n",
        "Let \\( X_1, X_2, ..., X_n \\) be a sequence of i.i.d. random variables with mean \\( \\mu \\) and standard deviation \\( \\sigma \\). Then, as \\( n \\) approaches infinity, the distribution of the sample mean \\( \\bar{X} \\) (or the sample sum \\( S_n \\)) approaches a normal distribution with mean \\( \\mu \\) and standard deviation \\( \\frac{\\sigma}{\\sqrt{n}} \\).\n",
        "\n",
        "**Significance of the Central Limit Theorem**:\n",
        "\n",
        "1. **Approximation of Population Distribution**: The Central Limit Theorem allows us to approximate the distribution of the sample mean or sum, regardless of the underlying distribution of the population, as long as the sample size is sufficiently large. This makes the normal distribution a powerful tool for statistical inference and hypothesis testing.\n",
        "\n",
        "2. **Statistical Inference**: The Central Limit Theorem forms the basis for many parametric statistical tests and procedures. It enables researchers to make inferences about population parameters (such as the population mean or variance) based on sample statistics, even when the population distribution is unknown or non-normal.\n",
        "\n",
        "3. **Sample Size Determination**: The Central Limit Theorem provides guidance on determining the appropriate sample size for statistical studies. It suggests that larger sample sizes lead to more reliable estimates of population parameters and narrower confidence intervals.\n",
        "\n",
        "4. **Quality Control and Process Improvement**: In manufacturing and quality control, the Central Limit Theorem is used to analyze process variability and identify deviations from expected performance. Control charts and process capability indices rely on the assumption of normally distributed sample statistics.\n",
        "\n",
        "5. **Random Sampling**: The Central Limit Theorem underscores the importance of random sampling in statistical studies. It demonstrates that the distribution of the sample mean or sum becomes increasingly normal as the sample size increases, reinforcing the validity of random sampling techniques in obtaining representative samples.\n",
        "\n",
        "In summary, the Central Limit Theorem is a cornerstone of statistical theory with wide-ranging applications in data analysis, inference, quality control, and decision-making. Its significance lies in its ability to provide insights into the behavior of sample statistics and their distribution, even when little is known about the population distribution."
      ],
      "metadata": {
        "id": "H4zAZJQ_KxtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10: State the assumptions of the Central Limit Theorem.**"
      ],
      "metadata": {
        "id": "soFUYvV0LJIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Central Limit Theorem (CLT) is a powerful statistical concept, but it relies on certain assumptions to hold true. These assumptions are essential for the validity of the theorem and the accurate application of its results. The main assumptions of the Central Limit Theorem are:\n",
        "\n",
        "1. **Independence**: The observations in the sample must be independent of each other. This means that the value of one observation should not affect the value of another observation. Independence is crucial to ensure that each observation contributes unique information to the sample.\n",
        "\n",
        "2. **Identically Distributed**: The random variables in the sample must be identically distributed. This means that each observation is drawn from the same population or distribution with the same probability distribution function (PDF) and parameters. Identical distribution ensures that the sample statistics accurately represent the population parameters.\n",
        "\n",
        "3. **Finite Variance**: The population distribution from which the sample is drawn must have a finite variance (\\( \\sigma^2 \\)). This assumption ensures that the sample mean or sum has a well-defined distribution and converges to a normal distribution as the sample size increases.\n",
        "\n",
        "4. **Large Sample Size**: The Central Limit Theorem is most accurate and applicable when the sample size (\\( n \\)) is sufficiently large. Although the exact threshold for \"sufficiently large\" may vary depending on the specific context, larger sample sizes generally lead to better approximations of the normal distribution.\n",
        "\n",
        "5. **Random Sampling**: The observations in the sample must be selected randomly from the population. Random sampling ensures that the sample is representative of the population and reduces the likelihood of sampling bias or systematic errors.\n",
        "\n",
        "These assumptions are fundamental to the Central Limit Theorem and must be carefully considered when applying the theorem in practice. Violation of these assumptions may lead to inaccurate or misleading results. Therefore, it is important to assess the validity of these assumptions in any statistical analysis involving the Central Limit Theorem."
      ],
      "metadata": {
        "id": "-K8NRv6lLGFL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YLPL9bDQJ6ZD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}